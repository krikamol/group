---
layout: page
permalink: /manifesto/
---

<p>The Rational Intelligence (RI) Lab was established to address emerging mathematical and practical challenges that arise at the interface between intelligent systems and society.</p>

<p>AI breakthroughs owe their triumph in part to processes where computers learn from past data to tackle intricate tasks. Rosenblatt's Perceptron algorithm (1957) was initial proof of a versatile learning rule, enabling computers not just to discern patterns but also to extrapolate to new scenarios. The domain has since seen a surge of more complex models and learning algorithms, from kernel machines to deep neural networks. Empowered by Vapnik's pioneering statistical guarantees (1998), this learning approach has revolutionised how we address scientific and engineering challenges.</p>

<p>In the wake of scaling computational power, the efficacy of the learning-based approach has surged, leading to the widespread adoption of modern AI systems across diverse platforms. Non-technical users now harness these capabilities, prompting the integration of AI into an extensive array of applications. However, this evolving landscape has given rise to new challenges that drive researchers to scrutinise the very foundation of machine learning. Notably, the efficacy of established techniques can stem from superficial data patterns vulnerable to real-world fluctuations. Moreover, while the flourishing heterogeneity of real-world datasets introduces prospects for collective intelligence and digital democratisation, it imposes limitations on inter-environment data sharing due to critical concerns like privacy, security, and equity. The frailty of prevailing learning methods in grappling with distributional shifts and adversarial attacks underscores their inability to quantify uncertainties beyond the purview of classical probability theory (Kolmogorov 1933). The need for novel solution concepts, e.g., in cooperative and non-cooperative game theory contexts (Nash 1950; Shapley 1951), becomes pronounced in the face of feedback loops and strategic manipulation. These trials collectively underscore the formidable gap that remains in our quest to engender machines with robust generalisation capacities.</p>

<p>Our research embraces and navigates these emerging complexities. We envision an expanded machine learning landscape, spanning algorithmic design, architectural considerations, data collection, and model deployment. Simultaneously, we recognize the imperative to redefine machine learning and generalisation in our modern context. On the one hand, knowledge of the data collection process illuminates a guiding beacon, empowering autonomous agents to ascend the ladder of causation (Pearl 2018), not only foreseeing intervention outcomes but also engaging in counterfactual reasoning. On the other hand, successful real-world model deployment mandates anticipation of novel uncertainties and incorporation of intrinsic heterogeneity, particularly those rooted in human preferences. The limitations of classical probability theory in quantifying broader uncertainties have been noted by Walley (1991) and subsequently by Shafer and Vovk (2019) and others. Finally, modern learning systems encompass more than minimising risk function; they entail eliciting, aggregating, open-sourcing, and trading algorithmic models. This reshapes the conventional communication model between AI engineers and its users. Amid these complexities, establishing rationality as a theoretical cornerstone for modern learning algorithms (Arrow 1951, von Neumann and Morgenstern 1944) becomes imperative.</p>

<p>Hence, our solutions demand an interdisciplinary fusion of computer science, statistics, machine learning, and economics. This synergy optimises the value derived from data, inference, and decisions. In essence, our research not only paves the path toward the creation of rational and intelligent systems, capable of engaging in interactions with complex environments, but also aids governmental and intergovernmental bodies in auditing, regulating, and mitigating real-world deployment risks and harms.</p>
